{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics as met\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "import os\n",
    "import errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make root folder the current working directory\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './reports/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_folder = './data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_data = './data/external/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(cleaned_folder+'x_train.csv')\n",
    "x_test = pd.read_csv(cleaned_folder+'x_test.csv')\n",
    "y_train = pd.read_csv(cleaned_folder+'y_train.csv')\n",
    "y_test = pd.read_csv(cleaned_folder+'y_test.csv')\n",
    "test_df = pd.read_csv(cleaned_folder+'test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test['TARGET']\n",
    "y_train = y_train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select algorithms to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'Gradient Boosting Classifier': GradientBoostingClassifier(), \n",
    "               'Ada Boost Classifier':AdaBoostClassifier(),\n",
    "               'Linear Discriminant Analyis': LinearDiscriminantAnalysis(),\n",
    "               'GaussianNB':GaussianNB(),\n",
    "               'BerNB':BernoulliNB(),\n",
    "               'KNN':KNeighborsClassifier(),\n",
    "               'Random Forest Classifier': RandomForestClassifier(),\n",
    "               'Decision Tree Classifier' : DecisionTreeClassifier(),\n",
    "               'Logistic Regression': LogisticRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run selected classifiers and select best algorithm to predict survival of test dataset\n",
    "base_accuracy = 0\n",
    "model_outcomes = []\n",
    "for Name,classify in classifiers.items():\n",
    "    classify.fit(x_train, y_train)\n",
    "    predicting_y = classify.predict(x_test)\n",
    "    model_outcomes.append({\n",
    "    'Algorithm': str(Name),\n",
    "    'Score': str(met.accuracy_score(y_test, predicting_y))\n",
    "    })\n",
    "\n",
    "    if met.accuracy_score(y_test,predicting_y) > base_accuracy:\n",
    "        base_accuracy = met.accuracy_score(y_test,predicting_y)\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.261259    168817\n",
       " 0.869467       543\n",
       " 1.434829       307\n",
       " 0.586785       184\n",
       " 3.085689        85\n",
       "              ...  \n",
       " 4.578813         1\n",
       " 7.806470         1\n",
       " 0.304669         1\n",
       " 8.712181         1\n",
       " 1.855460         1\n",
       "Name: REG_CITY_NOT_LIVE_CITY_AMT_ANNUITY, Length: 4906, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['REG_CITY_NOT_LIVE_CITY_AMT_ANNUITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.9181384703414076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Discriminant Analyis</td>\n",
       "      <td>0.9181384703414076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.9181384703414076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.9181003242418463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.918062178142285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.9118697946468307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BerNB</td>\n",
       "      <td>0.8690190094729481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.828698582236633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.7574162375230467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithm               Score\n",
       "1          Ada Boost Classifier  0.9181384703414076\n",
       "2   Linear Discriminant Analyis  0.9181384703414076\n",
       "8           Logistic Regression  0.9181384703414076\n",
       "0  Gradient Boosting Classifier  0.9181003242418463\n",
       "6      Random Forest Classifier   0.918062178142285\n",
       "5                           KNN  0.9118697946468307\n",
       "4                         BerNB  0.8690190094729481\n",
       "7      Decision Tree Classifier   0.828698582236633\n",
       "3                    GaussianNB  0.7574162375230467"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = pd.DataFrame(model_outcomes, columns=['Algorithm','Score'])\n",
    "model_scores.sort_values(by=['Score'] , ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove least important features through feature ranking with recursive feature elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model to run based on previously identified best predicting algorithm\n",
    "model = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10), scoring='accuracy' )\n",
    "rfecv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Number of features selected', fontsize=14, labelpad=20)\n",
    "plt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_df = pd.DataFrame()\n",
    "feature_imp_df['feature'] = x_train.columns\n",
    "feature_imp_df['importance'] = rfecv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order features by predictor value according to RFECV\n",
    "feature_imp_df.sort_values(by=['importance'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot features and their RFECV score\n",
    "feature_imp_df.plot.bar(x='feature', y='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = x_train.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most important features according to RFECV\n",
    "rfecv_features = columns[criteria]\n",
    "\n",
    "x_train = x_train[rfecv_features]\n",
    "x_test = x_test[rfecv_features]\n",
    "X_train = X_train[rfecv_features]\n",
    "test_df = test_df[rfecv_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run selected classifiers and select best algorithm to predict survival of test dataset\n",
    "base_accuracy = 0\n",
    "model_outcomes = []\n",
    "for Name,classify in classifiers.items():\n",
    "    classify.fit(x_train,y_train)\n",
    "    predicting_y = classify.predict(x_test)\n",
    "    model_outcomes.append({\n",
    "    'Algorithm': str(Name),\n",
    "    'Score': str(met.accuracy_score(y_test,predicting_y))\n",
    "    })\n",
    "\n",
    "    if met.accuracy_score(y_test,predicting_y) > base_accuracy:\n",
    "        #prediction = classify.predict(test_df)\n",
    "        base_accuracy = met.accuracy_score(y_test,predicting_y)\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = pd.DataFrame(model_outcomes, columns=['Algorithm','Score'])\n",
    "model_scores.sort_values(by=['Score'] , ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best algorithms and parameters by applying Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'Random_forest': {'model': RandomForestClassifier(), 'params' : {'n_estimators': [31, 35, 37]}},\n",
    "               'Logistic_regression': {'model': LogisticRegression(solver='liblinear', multi_class='auto'), \n",
    "                                       'params' : {'C': [1, 10, 100, 1000],\n",
    "                                       'penalty': ['l1','l2'],}},\n",
    "               'AdaBoostClassifier': {'model': AdaBoostClassifier(DecisionTreeClassifier(), random_state=7), 'params' :\n",
    "                                     {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n",
    "                                      \"base_estimator__splitter\" :   [\"best\", \"random\"],\n",
    "                                      \"learning_rate\":  [0.1, 0.3, 1.5]}},\n",
    "               'GradientBoostingClassifier': {'model' : GradientBoostingClassifier(), 'params' :\n",
    "                                     {'loss' : [\"deviance\"],\n",
    "                                      'n_estimators' : [360, 380, 400],\n",
    "                                      'learning_rate': [0.015, 0.02, 0.03],\n",
    "                                      'max_depth': [2, 3, 4],\n",
    "                                      'min_samples_leaf': [60, 70, 80],\n",
    "                                     }},\n",
    "               'KNearestNeighbors': {'model': KNeighborsClassifier(),\n",
    "                                     'params' : {'n_neighbors':[2, 5, 7],\n",
    "                                         'metric':['euclidean', 'minkowski']}},\n",
    "\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for model_name, mp in classifiers.items():\n",
    "    grid = GridSearchCV(mp['model'], mp['params'], cv=10, return_train_score=False, n_jobs=-1)\n",
    "    grid.fit(X_train,y)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid.best_score_,\n",
    "        'best_params': grid.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = pd.DataFrame(scores, columns=['model','best_score','best_params'])\n",
    "model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBC = GradientBoostingClassifier(learning_rate=0.02, \n",
    "                                 loss='deviance', \n",
    "                                 max_depth=3, \n",
    "                                 min_samples_leaf=70, \n",
    "                                 n_estimators=380)\n",
    "RBC.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = RBC.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate table of predictions vs actual\n",
    "pd.crosstab(Y_pred_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_pred_train, Y_train))\n",
    "print()\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(Y_pred_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = RBC.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Submission File\n",
    "predicted_test_values = pd.DataFrame({'SK_ID_CURR': SK_ID_CURR,'TARGET' :prediction})\n",
    "predicted_test_values.to_csv(external_data + 'Submission_file.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
