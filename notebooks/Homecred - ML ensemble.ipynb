{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potentential improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Include more parameters as part of the Hyper Parameter Tuning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics as met\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.stats import randint\n",
    "import os\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%flake8_on\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "output_folder = './reports/figures/'\n",
    "cleaned_folder = './data/processed/'\n",
    "external_data = './data/external/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(cleaned_folder+'x_train.csv')\n",
    "x_test = pd.read_csv(cleaned_folder+'x_test.csv')\n",
    "y_train = pd.read_csv(cleaned_folder+'y_train.csv')\n",
    "y_test = pd.read_csv(cleaned_folder+'y_test.csv')\n",
    "test_df = pd.read_csv(cleaned_folder+'test_df.csv')\n",
    "test_ids_df = pd.read_csv(cleaned_folder+'test_ids_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test['TARGET']\n",
    "y_train = y_train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    168267\n",
       "1.0     15238\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the dataset is balanced\n",
    "y_train.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge outcome variable & features\n",
    "train_df = pd.concat([x_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset based on outcome variable\n",
    "no_pay_prob = train_df[train_df['TARGET'] == 0]\n",
    "pay_prob = train_df[train_df['TARGET'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:80: E501 line too long (103 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "# upsample - artificially add customers with payment difficulties\n",
    "pay_prob2 = resample(pay_prob,\n",
    "                     replace=True,  # sample with replacement\n",
    "                     n_samples=len(no_pay_prob),  # dataset to match customers without payment problems\n",
    "                     random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168267, 27)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of customers with payment difficulties\n",
    "no_pay_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168267, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New count of customers without payment difficulties\n",
    "pay_prob2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataset with added cases\n",
    "train_df = pd.concat([pay_prob2, no_pay_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset in preparation of modelling\n",
    "y_train = train_df['TARGET']\n",
    "x_train = train_df.drop('TARGET', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'Gradient Boosting Classifier': GradientBoostingClassifier(),\n",
    "               'Ada Boost Classifier': AdaBoostClassifier(),\n",
    "               'Linear Discriminant Analyis': LinearDiscriminantAnalysis(),\n",
    "               'GaussianNB': GaussianNB(),\n",
    "               'BernoulliNB': BernoulliNB(),\n",
    "               'KNN': KNeighborsClassifier(),\n",
    "               'Random Forest Classifier': RandomForestClassifier(),\n",
    "               'Decision Tree Classifier': DecisionTreeClassifier(),\n",
    "               'Logistic Regression': LogisticRegression()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is used to evaluate algorithm performance. The reason for this is that:\n",
    "- The original dataset is unbalanced; most people don't have payment difficulties\n",
    "- The objective of this analysis is to correctly identify customers with payment difficulties\n",
    "\n",
    "Recall = the number of correctly classified customers with payment difficulties = True Positives / (True Positives + False Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:80: E501 line too long (87 > 79 characters)\n",
      "9:5: E122 continuation line missing indentation or outdented\n",
      "10:5: E122 continuation line missing indentation or outdented\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate strongest predicting algorithm\n",
    "# (step can be removed by selected previous strongest algorithm to speed-up processing)\n",
    "base_score = 0\n",
    "model_outcomes = []\n",
    "for Name, classify in classifiers.items():\n",
    "    classify.fit(x_train, y_train)\n",
    "    predicting_y = classify.predict(x_test)\n",
    "    model_outcomes.append({\n",
    "    'Algorithm': str(Name),\n",
    "    'Recall_score': str(met.recall_score(y_test, predicting_y))\n",
    "    })\n",
    "\n",
    "    if met.recall_score(y_test, predicting_y) > base_score:\n",
    "        # prediction = classify.predict(test_df)\n",
    "        base_score = met.recall_score(y_test, predicting_y)\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.7340789064926996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.6680646163404784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.6169617893755824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Discriminant Analyis</td>\n",
       "      <td>0.6149425287356322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6147872009940976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.6006523765144455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.28191985088536814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.11432121776949364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.0006213109661385523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithm           Recall_score\n",
       "3                    GaussianNB     0.7340789064926996\n",
       "4                   BernoulliNB     0.6680646163404784\n",
       "1          Ada Boost Classifier     0.6169617893755824\n",
       "2   Linear Discriminant Analyis     0.6149425287356322\n",
       "8           Logistic Regression     0.6147872009940976\n",
       "0  Gradient Boosting Classifier     0.6006523765144455\n",
       "5                           KNN    0.28191985088536814\n",
       "7      Decision Tree Classifier    0.11432121776949364\n",
       "6      Random Forest Classifier  0.0006213109661385523"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (82 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "model_scores = pd.DataFrame(model_outcomes, columns=['Algorithm', 'Recall_score'])\n",
    "model_scores.sort_values(by=['Recall_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best algorithms according to \n",
    "- Random Forest\n",
    "- Decision Tree\n",
    "- K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 selected features\n"
     ]
    }
   ],
   "source": [
    "rf_feature_select = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "rf_feature_select.fit(x_train, y_train)\n",
    "\n",
    "rf_sel_feature_count = rf_feature_select.get_support()\n",
    "rf_selected_features = x_train.loc[:, rf_sel_feature_count].columns.tolist()\n",
    "print(str(len(rf_selected_features)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elected features: ['REGION_POPULATION_RELATIVE_DAYS_REGISTRATION', 'DAYS_REGISTRATION_DAYS_LAST_PHONE_CHANGE', 'DAYS_LAST_PHONE_CHANGE_AMT_ANNUITY', 'REGION_POPULATION_RELATIVE_DAYS_EMPLOYED', 'DAYS_EMPLOYED_AMT_INCOME_TOTAL', 'DAYS_BIRTH_AMT_INCOME_TOTAL', 'DAYS_REGISTRATION_AMT_GOODS_PRICE', 'DAYS_EMPLOYED_CNT_FAM_MEMBERS', 'DAYS_ID_PUBLISH_DAYS_LAST_PHONE_CHANGE', 'DAYS_ID_PUBLISH_AMT_GOODS_PRICE', 'CNT_FAM_MEMBERS_DAYS_LAST_PHONE_CHANGE', 'REGION_POPULATION_RELATIVE_DAYS_ID_PUBLISH', 'DAYS_EMPLOYED_AMT_ANNUITY', 'DAYS_EMPLOYED_DAYS_LAST_PHONE_CHANGE', 'DAYS_EMPLOYED_DAYS_REGISTRATION', 'REGION_POPULATION_RELATIVE_DAYS_LAST_PHONE_CHANGE']\n"
     ]
    }
   ],
   "source": [
    "print('elected features:', rf_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select strongest features\n",
    "x_train = x_train[rf_selected_features]\n",
    "x_test = x_test[rf_selected_features]\n",
    "test_df = test_df[rf_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:80: E501 line too long (87 > 79 characters)\n",
      "9:5: E122 continuation line missing indentation or outdented\n",
      "10:5: E122 continuation line missing indentation or outdented\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate strongest predicting algorithm\n",
    "# (step can be removed by selected previous strongest algorithm to speed-up processing)\n",
    "base_score = 0\n",
    "model_outcomes = []\n",
    "for Name, classify in classifiers.items():\n",
    "    classify.fit(x_train, y_train)\n",
    "    predicting_y = classify.predict(x_test)\n",
    "    model_outcomes.append({\n",
    "    'Algorithm': str(Name),\n",
    "    'Recall_score': str(met.recall_score(y_test, predicting_y))\n",
    "    })\n",
    "\n",
    "    if met.recall_score(y_test, predicting_y) > base_score:\n",
    "        # prediction = classify.predict(test_df)\n",
    "        base_score = met.recall_score(y_test, predicting_y)\n",
    "\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.7691829760795278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.666511338925132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Discriminant Analyis</td>\n",
       "      <td>0.6439888164026095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.6425908667287977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.6298539919229574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.5984777881329606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.2775706741223983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.09863311587449518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Algorithm         Recall_score\n",
       "3                    GaussianNB   0.7691829760795278\n",
       "4                   BernoulliNB    0.666511338925132\n",
       "2   Linear Discriminant Analyis   0.6439888164026095\n",
       "8           Logistic Regression   0.6425908667287977\n",
       "1          Ada Boost Classifier   0.6298539919229574\n",
       "0  Gradient Boosting Classifier   0.5984777881329606\n",
       "5                           KNN   0.2775706741223983\n",
       "7      Decision Tree Classifier  0.09863311587449518\n",
       "6      Random Forest Classifier                  0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (82 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "model_scores = pd.DataFrame(model_outcomes, columns=['Algorithm', 'Recall_score'])\n",
    "model_scores.sort_values(by=['Recall_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentential classifiers to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:80: E501 line too long (107 > 79 characters)\n",
      "6:80: E501 line too long (108 > 79 characters)\n",
      "7:80: E501 line too long (98 > 79 characters)\n",
      "8:80: E501 line too long (98 > 79 characters)\n",
      "9:80: E501 line too long (85 > 79 characters)\n",
      "10:80: E501 line too long (84 > 79 characters)\n",
      "12:80: E501 line too long (89 > 79 characters)\n",
      "13:80: E501 line too long (94 > 79 characters)\n",
      "14:80: E501 line too long (80 > 79 characters)\n",
      "15:80: E501 line too long (92 > 79 characters)\n",
      "18:80: E501 line too long (87 > 79 characters)\n",
      "20:80: E501 line too long (86 > 79 characters)\n",
      "21:80: E501 line too long (84 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Random_forest': {'model': RandomForestClassifier(),\n",
    "                                 'params': {'n_estimators': [31, 35, 37]}},\n",
    "               'Logistic_regression': {'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "                                       'params': {'C': [1, 10, 100, 1000],\n",
    "                                                  'penalty': ['l1', 'l2'], }},\n",
    "               'AdaBoostClassifier': {'model': AdaBoostClassifier(DecisionTreeClassifier(), random_state=7),\n",
    "                                      'params': {'base_estimator__criterion': [\"gini\", \"entropy\"],\n",
    "                                                 'base_estimator__splitter':   [\"best\", \"random\"],\n",
    "                                                 'learning_rate':  [0.1, 0.3, 1.5]}},\n",
    "               'GradientBoostingClassifier': {'model': GradientBoostingClassifier(),\n",
    "                                              'params': {'loss': [\"deviance\"],\n",
    "                                                         'n_estimators': [360, 380, 400],\n",
    "                                                         'learning_rate': [0.015, 0.02, 0.03],\n",
    "                                                         'max_depth': [2, 3, 4],\n",
    "                                                         'min_samples_leaf': [60, 70, 80]}},\n",
    "               'KNearestNeighbors': {'model': KNeighborsClassifier(),\n",
    "                                     'params': {'n_neighbors': [2, 5, 7],\n",
    "                                                'metric': ['euclidean', 'minkowski']}},\n",
    "               'DecisionTreeClassifier': {'model': KNeighborsClassifier(),\n",
    "                                          'params': {'criterion': [\"gini\", \"entropy\"],\n",
    "                                                     'splitter': ['best', 'random'],\n",
    "                                                     'max_depth': [3, None],\n",
    "                                                     'max_features': [1, 5, 9],\n",
    "                                                     'min_samples_leaf': [1, 5, 9]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected classifiers based on model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (107 > 79 characters)\n",
      "4:80: E501 line too long (88 > 79 characters)\n",
      "5:80: E501 line too long (83 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Logistic_regression': {'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "                                       'params': {'C': [1, 10, 100, 1000],\n",
    "                                                  'penalty': ['l1', 'l2'], }},\n",
    "               'LinearDiscriminant': {'model': LinearDiscriminantAnalysis(solver='svd'),\n",
    "                                      'params': {'tol': [0.0001, 0.0002, 0.0003]}},\n",
    "               'BernoulliNB': {'model': BernoulliNB(),\n",
    "                               'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:80: E501 line too long (107 > 79 characters)\n",
      "4:80: E501 line too long (88 > 79 characters)\n",
      "5:80: E501 line too long (83 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "# Select classifier algorithms to optimise\n",
    "# NB: GaussianNB doesn't have any parameters to optimise\n",
    "classifiers = {'Logistic_regression': {'model': LogisticRegression(solver='liblinear', multi_class='auto'),\n",
    "                                       'params': {'C': [1, 10, 100, 1000],\n",
    "                                                  'penalty': ['l1', 'l2'], }},\n",
    "               'LinearDiscriminant': {'model': LinearDiscriminantAnalysis(solver='svd'),\n",
    "                                      'params': {'tol': [0.0001, 0.0002, 0.0003]}},\n",
    "               'BernoulliNB': {'model': BernoulliNB(),\n",
    "                               'params': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]}}}\n",
    "\n",
    "scores = []\n",
    "for model_name, mp in classifiers.items():\n",
    "    grid = GridSearchCV(mp['model'],\n",
    "                        mp['params'],\n",
    "                        cv=10,\n",
    "                        scoring='recall',\n",
    "                        return_train_score=False,\n",
    "                        n_jobs=-1)\n",
    "    grid.fit(x_train, y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid.best_score_,\n",
    "        'best_params': grid.best_params_\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_scores = pd.DataFrame(model_outcomes, columns=['Algorithm', 'Recall_score'])\n",
    "model_scores.sort_values(by=['Recall_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.663963</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearDiscriminant</td>\n",
       "      <td>0.641385</td>\n",
       "      <td>{'tol': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic_regression</td>\n",
       "      <td>0.639781</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                best_params\n",
       "2          BernoulliNB    0.663963            {'alpha': 0.01}\n",
       "1   LinearDiscriminant    0.641385            {'tol': 0.0001}\n",
       "0  Logistic_regression    0.639781  {'C': 1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table with best parameters per algorithm\n",
    "model_parameters = pd.DataFrame(scores, columns=['model',\n",
    "                                                 'best_score',\n",
    "                                                 'best_params'])\n",
    "model_parameters.sort_values(by=['best_score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the earlier identified top 3 algorithms with best performing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "model1 = RandomForestClassifier(\n",
    ")\n",
    "model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "model2 = DecisionTreeClassifier(criterion='gini',\n",
    "                                max_depth=None, max_features=5,\n",
    "                                min_samples_leaf=1, splitter='random')\n",
    "model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "model3 = KNeighborsClassifier('metric': 'euclidean', 'n_neighbors': 2\n",
    ")\n",
    "model3.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model based on training data\n",
    "predict_1 = model1.predict(x_train)\n",
    "predict_2 = model2.predict(x_train)\n",
    "predict_3 = model3.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, predict_1[:, 1], pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, predict_2[:, 1], pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, predict_3[:, 1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1[:, 1])\n",
    "auc_score2 = roc_auc_score(y_test, pred_prob2[:, 1])\n",
    "\n",
    "print(auc_score1, auc_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr1, tpr1, linestyle='--', color='orange', label='Random forest')\n",
    "plt.plot(fpr2, tpr2, linestyle='--', color='green', label='Decision Tree')\n",
    "plt.plot(fpr3, tpr3, linestyle='--', color='purple', label='KNN')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "print(\"Confusion matrix\")\n",
    "y_actual = pd.Series(y_train, name='Actual')\n",
    "y_predicted = pd.Series(y_pred_train, name='Predicted')\n",
    "pd.crosstab(y_actual, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train\n",
    "#.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(y_pred_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions based on generated model\n",
    "prediction = algorithm.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Submission File\n",
    "SK_ID_CURR = list(test_ids_df['SK_ID_CURR'])\n",
    "predicted_test_values = pd.DataFrame({'SK_ID_CURR': SK_ID_CURR,'TARGET' :prediction})\n",
    "predicted_test_values.to_csv(external_data + 'Submission_file.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
